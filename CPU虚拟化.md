# CPU虚拟化

## 第二章—操作系统介绍

### **操作系统的任务**

操作系统：负责确保系统既易于使用又正确高效地运行。

它取得CPU、内存或磁盘等物理资源，甚对它们进行虚拟化。

它处理与并发有关的麻烦且棘手的问题。

它持久地（persistently）存储文件，并保证其安全性。

### 虚拟化

将物理资源转化为更通用、更强大且更易于使用的虚拟形式。我们有时候将操作系统称为**虚拟机**。

为了让应用程序告诉操作系统要做什么，操作系统**提供了许多API**（接口），有时候也说是操作系统为应用程序提供了一个标准库

操作系统也被称为**资源管理器**。他让多个程序运行，共享cpu，让许多程序访问设备，同时访问自己的指令和数据

**虚拟化CPU**

将单个CPU(或其中一小部分)转换为看似无限数量的CPU，从而让许多程序看似同时运行，这就是所谓的虚拟化CPU

**虚拟化内存**

每个进程都有自己的私有虚拟地址空间，操作系统以某种方式映射到机器的物理内存上，一个正在运行的程序的内存引用不会影响其他进程。

> **CPU**：通常使用时间片、多核的方法达到对CPU的分割；
> **内存**：内存是CPU可以进行直接寻址的存储空间，通常使用分段、分页的手段达到逻辑分割；
> IO：即输入\输出，以网卡、磁盘为例：
> **磁盘**：采用磁盘映像文件的方式实现分割，通常采用Spare格式（稀疏格式：牺牲性能，虚拟化超出本身的内存空间）
> **网卡**：通过软件的方式，获得虚拟化网卡。

### 设计目标

1.建立一些抽象，让系统方便使用

2.提供高性能

3.在应用程序和OS之间，以及应用程序之间提供保护

4.高度的可靠性和安全性

## 第四章—抽象：进程

### 知识点

**进程非正式定义**

进程就是运行中的程序

**时分共享cpu技术**

通过让一个进程只运行一个时间片，然后切换到其他进程，操作系统提供了存在多个虚拟 CPU 的假象

**上下文切换**

它让操作系统能够停止运行一个程序，并开始在给定的 CPU 上运行另一个程序。

**抽象-进程**

操作系统为正在运行的程序提供的抽象，就是所谓的进程。进程是操作系统进行资源分配和调度的一个独立单位

进程的机器状态：

1. 内存，进程可以访问的内存（称为地址空间，address space）是该进程的一部分。
2. 寄存器：许多指令明确地读取或更新寄存器。
3. 还有一些特殊的寄存器，如PC，栈指针，帧指针。

**一个进程包括五个部分**

1. （OS管理运行程序的）数据结构P
2. （运行程序的）内存代码C
3. （运行程序的）内存数据D
4. （运行程序的）通用寄存器信息R
5. （OS控制程序执行的）程序状态字信息PSW

**进程API**

创建（create）
销毁（destroy）
等待（wait）
其他控制（miscellaneous control）
状态（status）

**进程创建**

1、将代码和所有静态数据（例如初始化变量）加载（load）到内存中，加载到进程的地址空间中。

2、为程序的运行时栈（run-time stack 或 stack）分配一些内存

3、也可能为程序的堆（heap）分配一些内存

4、一些其他初始化任务，特别是与输入/输出（I/O）相关的任务

5、启动程序，在入口处运行，即 main()。通过跳转到 main()例程（第 5 章讨论的专门机制），OS 将 CPU的控制权转移到新创建的进程中，从而程序开始执行。

**进程的状态**

三种基本状态：

1、运行（running）：在运行状态下，进程正在处理器上运行。这意味着它正在执行指令。
2、就绪（ready）：在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。
3、阻塞（blocked）：在阻塞状态下，一个进程执行了某种操作，直到发生其他事件时才会准备运行。一个常见的例子是，当进程向磁盘发起 I/O 请求时，它会被阻塞，因此其他进程可以使用处理器。

![image-20211111130118589](https://gitee.com/nnilk/cloudimage/raw/master/img/202111111301668.png)

其他可能存在的状态：

**挂起状态**（是该进程暂时不接受调度）。

**创建状态**：此时，进程已经拥有了字节的PCB，但该进程所必需的资源或其它信息（如主存资源）尚未分配，进程自身还未进入主存，即创建工作尚未完成，进程还不能够被调度运行。

（创建进程的两个步骤： 为一个新进程创建PCB，并填写必要管理信息；把该进程转入就绪状态并插入就绪队列。）

**终止状态**：进程的终止首先要等待操作系统进行善后处理，然后将其PCB清零，并将PCB空间返还系统。

**进程控制块（Process Control Block）**

PCB是OS用于记录和刻画进程状态及环境信息的数据结构

借助PCB，OS可以全面管理进程物理实体，刻画进程的执行现状，控制进程的执行

### 课后习题

**4.1**

**用以下标志运行程序：./process-run.py -l 5:100,5:100。CPU 利用率（CPU 使用时间的百分比）应该是多少？为什么你知道这一点？利用 -c 标记查看你的答案是否正确。**

运行结果如下

**cpu利用率为100%**，可以看到进程0和进程1交替执行，且没有调用IO命令。

![image-20211107224505762](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943336.png)

加上-c标记后运行结果。CPU一直处于占用状态，验证正确

![image-20211107224328317](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943337.png)



**4.2**

**现在用这些标志运行：./process-run.py -l 4:100,1:0。这些标志指定了一个包含 4 条指令的进程（都要使用 CPU），并且只是简单地发出 I/O 并等待它完成。完成这两个进程需要多长时间？利用-c 检查你的答案是否正确。**

从运行结果来看，进程0的4条指令需要占用4个cpu时间，发起io和io结束需要2个时装周期 ，io占用时间还无法得知。total=4+2+n

![](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943338.png)



加上-c标记后运行结果，可以看到程序一共占用了11个时钟周期，io占用了5时钟周期

![](https://gitee.com/nnilk/cloudimage/raw/master/img/202111120937254.png)



**4.3**

**现在交换进程的顺序：./process-run.py -l 1:0,4:100。现在发生了什么？交换顺序是否重要？为什么？同样，用-c 看看你的答案是否正确。**

交换运行顺序后，首先运行进程0，进程0发起IO，系统进行上下文切换，进程1占用cpu执行程序。

![image-20211109170627689](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943340.png)

加上-c，可以看到，让进程0先执行IO的话，进程1在进程0调用IO的同时可占用CPU。只需6个时钟周期即可执行完程序

![image-20211109171420829](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943341.png)



**4.4**

**现在交换进程的顺序：./process-run.py -l 1:0,4:100。现在发生了什么？交换顺序是否重要？为什么？同样，用-c 看看你的答案是否正确。**

可以看到，因为进程在进行I/O操作时，系统不会进行上下文切换，所以进程1只能等待进程0调用IO结束再占用CPU，最终要消耗9个时钟周期

![image-20211109172648650](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943342.png)



**4.5**

**现在，运行相同的进程，但切换行为设置，在等待I/O 时切换到另一个进程（-l 1:0,4:100-c -S SWITCH_ON_IO）。现在会发生什么？利用-c 来确认你的答案是否正确。**

可以看到，让进程0先执行IO，然后系统进行上下文切换，进程1可占用CPU。只需6个时钟周期即可执行完程序

![image-20211109172752093](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943343.png)



## 第五章-进程API

### 知识点

#### **fork系统调用**

1、子进程不会从 main()函数开始执行，而是直接从 fork()系统调用返回。

2、子进程拥有自己的地址空间（即拥有自己的私有内存）、寄存器、程序计数器等

3、父进程获得的返回值是新创建子进程的 PID，而子进程获得的返回值是 0

4、子进程和父进程的运行顺序取决于CPU调度顺序

**代码实现**

```c
 #include <stdio.h>
 #include <stdlib.h>
 #include <unistd.h>

 int main(int argc, char *argv[])
 {
 printf("hello world (pid:%d)\n", (int) getpid());
 int rc = fork();
 if (rc < 0) { // fork failed; exit
 fprintf(stderr, "fork failed\n");
 exit(1);
 } else if (rc == 0) { // child (new process)
 printf("hello, I am child (pid:%d)\n", (int) getpid());
 } else { // parent goes down this path (main)
 printf("hello, I am parent of %d (pid:%d)\n",
 rc, (int) getpid());
 }
 return 0;
 }
```

#### wait系统调用

父进程调用 wait()，延迟自己的执行，直到子进程执行完毕。当子进程结束，wait()才返回父进程。

代码实现

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int main(int argc, char *argv[])
 {
 printf("hello world (pid:%d)\n", (int) getpid());
 int rc = fork();
 if (rc < 0) { // fork failed; exit
 fprintf(stderr, "fork failed\n");
 exit(1);
 } else if (rc == 0) { // child (new process)
 printf("hello, I am child (pid:%d)\n", (int) getpid());
 } else { // parent goes down this path (main)
 int wc = wait(NULL);
 printf("hello, I am parent of %d (wc:%d) (pid:%d)\n",
 rc, wc, (int) getpid());
 }
 return 0;
 }
```

运行结果

```
prompt> ./p2
hello world (pid:29266)
hello, I am child (pid:29267)
hello, I am parent of 29267 (wc:29267) (pid:29266)
prompt>
```

#### exec系统调用

这个系统调用可以让子进程执行与父进程不同的程序。例如，在p2.c 中调用 fork()，这只是在你想运行相同程序的拷贝谁有用。但是，我们常常想运行不同的程序，exec()正好做这样的事

这个例子中，子进程调用 execvp()来运行字符计数程序 wc。

exec()会从可执行程序中加载代码和静态数据，并用它覆写自己代码段（以及静态数据），堆、栈及其他内存空间也会被重新初始化。然后操作系统就执行该程序，将参数通过 argv 传递给该进程。因此，它并没有创建新进程，而是直接将当前运行的程序（以前的 p3）替换为不同的运行程序（wc）。子进程执行 exec()之后，几乎就像p3.c 从未运行过一样。对 exec()的成功调用永远不会返回

```
prompt> ./p3
hello world (pid:29383)
hello, I am child (pid:29384)
29 107 1030 p3.c
hello, I am parent of 29384 (wc:29384) (pid:29383)
prompt>
```

```c
 #include <stdio.h>
 #include <stdlib.h>
 #include <unistd.h>
 #include <string.h>
 #include <sys/wait.h>

 int
 main(int argc, char *argv[])
 {
 printf("hello world (pid:%d)\n", (int) getpid());
 int rc = fork();
 if (rc < 0) { // fork failed; exit
 fprintf(stderr, "fork failed\n");
 exit(1);
 } else if (rc == 0) { // child (new process)
 printf("hello, I am child (pid:%d)\n", (int) getpid());
 char *myargs[3];
 myargs[0] = strdup("wc"); // program: "wc" (word count)
 myargs[1] = strdup("p3.c"); // argument: file to count
 myargs[2] = NULL; // marks end of array
 execvp(myargs[0], myargs); // runs word count
 printf("this shouldn't print out");
 } else { // parent goes down this path (main)
 int wc = wait(NULL);
 printf("hello, I am parent of %d (wc:%d) (pid:%d)\n",
 rc, wc, (int) getpid());
 }
 return 0;
 }
```

#### why splits fork()  and exec()

在构建UNIX shell 的时候非常有用，因为这给了shell 在fork 之后exec 之前运行代码的机会，这些代码可以在运行新程序前改变环境，实现一些有趣的功能。

例`prompt> wc p3.c > newfile.txt`
在上面的例子中，wc 的输出结果被重定向（redirect）到文件newfile.txt 中（通过newfile.txt之前的大于号来指明重我向）。shell 实现结果重定向的方式也很简单，当完成子进程的创建
后，shell在调用exec()之前先关闭了标准输出（standardoutput），打开了文件newfile.txt。这样，即将运行的程序wc 的输出结果就被发送到该文件，而不是打印在屏幕上。



### 课后习题

**5.1**

**编写一个调用 fork()的程序。谁调用 fork()之前，让主进程访问一个变量（例如 x）并将其值设置为某个值（例如 100）。子进程中的变量有什么值？当子进程和父进程都改变x 的值，变量会发生什么？**

测试代码：

```c
#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>


void test1() {//在调用之前,让主进程访问一个变量(例如 x)并将其值设               //置为100
    int pid = fork();
    int x = 100;
    if (pid < 0) {
        printf("fork error\n");
        exit(1);
    } else if (pid == 0) {
        printf("child, x %d\n", x);
    } else {
        printf("parent, x %d\n", x);
    }
}

void test2() {
    int pid = fork();
    int x = 100;
    if (pid < 0) {
        printf("fork error\n");
        exit(1);
    } else if (pid == 0) {  //当子进程和父进程都改变 x 的值时
        printf("child,x %d\n", x);
        x = 0;
        printf("child,x %d\n", x);
    } else {
        printf("parent,x %d\n", x);
        x = 1;
        printf("parent,x %d\n", x);
    }
}

int main(int argc, char *argv[]) {
    if (argc == 1) {
        test1();
    } else {
        test2();
    }
    return 0;
}

```

可以看到，在调用之前,让主进程访问一个变量(例如 x)并将其值设为100，父进程和子进程的x值都为100

![image-20211109174929408](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943344.png)

当子进程和父进程在各自进程修改x值时，父子进程的值各自不受影响

![image-20211109173934825](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943345.png)



**5.2**

**编写一个打开文件的程序（使用 open()系统调用），然后调用 fork()创建一个新进程。子进程和父进程都可以访问 open()返回的文件描述符吗？当它在并发（即同时）写入文件时，会发生什么？**

测试代码：

```c
#include <fcntl.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/wait.h>
#include <unistd.h>

int main() {
    int fd = open("./check.txt", O_CREAT | O_RDWR | O_TRUNC, S_IRWXU);
    int pid = fork();
    if (pid < 0) {
        printf("fork error\n");
        exit(1);
    } else if (pid == 0) {
        char *buf = "child\n";
        int error = write(fd, buf, sizeof(char) * strlen(buf));
        printf("child error: %d\n", error == -1 ? 1 : 0);

    } else {
        char *buf = "parent\n";
        int error = write(fd, buf, sizeof(char) * strlen(buf));
        printf("child error: %d\n", error == -1 ? 1 : 0);

        int wc = wait(NULL);
        close(fd);
    }
    return 0;
}
```

运行结果如下，可以看到

父进程，子进程都能访问open返回的fd文件符。当他们同时写入文件时，存在竞争条件，但因为操作系统会进行调度，所以最终两个进程都能写入成功

![image-20211109180303635](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943346.png)

![image-20211109180212533](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943347.png)



**5.4**

**编写一个调用 fork()的程序,然后调用某种形式的 exec()来运行序"/bin/ls"看看是否可以尝试 exec 的所有变体,包括 execl()、 execle()、 execlp()、 execv()、 execvp()和 execve(),为什么同样的基本调用会有这么多变种？**

测试代码

```

#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(int argc, char *argv[], char *envp[]) {
  int pid = fork();
  char *cmd = "/bin/ls";
  char *arg[] = {"ls", "-a", NULL};

  if (pid < 0) {
    printf("fork error\n");
    exit(1);
  } else if (pid == 0) {
    //    exec不会返回,所以第一条execl语句后的语句不会被执行
    execl(cmd, "ls", NULL);
    execlp(cmd, "ls", NULL);
    execve(cmd, arg, envp);
    execv(cmd, arg);
    execvp(cmd, arg);
    execle(cmd, "ls", NULL, envp);
    execvP(cmd,arg)
  } else {
  }
  return 0;
}
```

以下是调用各个形式的exec函数后程序的运行结果

exec 多个变体能提供不同的功能,不同后缀指示着不同的操作功能：

1. l: 希望接收以逗号分隔的参数列表,列表以 NULL 指针作为结束标志
2. v: 希望接收一个以 NULL 结尾字符串数组的指针
3. p: 是一个以 NULL 结尾的字符串数组指针,函数可以利用 DOS 的 PATH 变量查找自程序文件
4. e： 函数传递指定采纳数 envp(环境变量),允许改变子进程环境,无后缀 e 是,子进程使用当前程序环境
5. c 语言没有默认参数语法,只能实现多个变体

execl:

![image-20211109195822756](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943348.png)

execlp:

![image-20211109195938552](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943349.png)

execve：

![image-20211109200052709](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943350.png)

execv：

![image-20211109200128674](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943351.png)

execvp：

![image-20211109200209564](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943352.png)

execle：

![image-20211109200430882](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943353.png)

execlP：

![image-20211109200543452](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943354.png)

## 第六章——受限直接执行

### 受限运行协议

**用户模式** user mode：在用户模式下运行的代码会受到限制，如用户模式下，进程不能发出I/O，这样会引发异常，可能导致操作系统终止该进程

**内核模式** kernel mode：操作系统就在内核模式下运行，在此模式下，运行的代码可以做它想做的所有事，包括特权操作，发出I/O和执行所有类型的受限制操作

受限直接运行**有两个阶段**：
1，系统引导时：内核初始化陷阱表，CPU记住陷阱表的位置以供使用
2，运行进程时：在执行进程前，操作系统为进程初始化了一些内容，接着转入用户模式运行程序。当进程发起系统调用时，会重新陷入操作系统，然后通过陷阱返回，并将控制权重新交给进程

通过让进程在用户模式和内核模式间切换，就完成了保护操作系统的控制权，且限制进程的运行，让它不能做不应该做的事

![image-20220109081403999](https://s2.loli.net/2022/01/09/k2O1dHJv7jxi5Is.png)

![image-20220109081547409](https://s2.loli.net/2022/01/09/IHiywGmulDKWvEU.png)

操作系统通过时钟中断重新获得了CPU的控制权，那么它需要决定：是继续运行当前的进程，还是切换其它进程，这个决定是由调度程序做出的，它是操作系统的一部分，这里先说明如何切换进程

如果决定切换进程，OS就会执行一些底层代码，即上下文切换：操作系统为当前正执行的进程保存它寄存器的值，并为即将执行的进程恢复寄存器的值，这样操作系统可以确保从内核模式返回时，去执行另一个进程而不是之前运行的进程

下面是进程A，B间切换的一张表，操作系统决定从当前正在运行的进程A切换到进程B，它调用switch()，该系统调用会保存当前运行进程的寄存器的值(保存到A的进程结构)，将B的进程结构恢复到寄存器，从内核模式退出到用户模式，进入B进程执行代码

## 第七章——进程调度

### 知识点

#### **调度指标**

周转时间：T ~周转时间~= T ~完成时间~−T ~到达时间~

响应时间：T~响应时间~= T ~首次运行~−T ~到达时间~

公平性：每个进程都有得到调度的机会

#### FIFO（先来先服务）

优点：它很简单，而且易于实现

缺点：护航效应，一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后。导致很差的平均周转时间

#### SJF（最短任务优先）

考虑到所有工作同时到达的假设，先运行最短的任务，然后是次短的任务，如此下去。

我们可以证明SJF 确实是一个最优的调度算法（假设所有任务同时到达）

#### 最短完成时间优先（STCF）

每当新工作进入系统时，它就会确定剩余工作和新工作中，谁的剩余时间最少，然后调度该工作。

允许抢占，放宽假设，所有任务不是同时到达的

优点：结果是平均周转时间大大提高，虑到我们的新假设，STCF 可证明是最优的。考虑到如果所有工作同时到达，SJF 是最优的

![image-20211111205039567](https://gitee.com/nnilk/cloudimage/raw/master/img/202111112050629.png)

#### 轮转（RR）

基本思想：RR 在一个时间片（time slice，有时称为调度scheduling quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。它反复执行，直到所有任务完成。

【请注意，时间片长度必须是时钟中断周期的倍数。】

时间片长度对于RR 是至关重要的。
时间片太短是有问题的：突然上下文切换的成本将影响整体性能。因此，系统设计者需要权衡时间片的长度，使其足够长，以便摊销（amortize）上下文切换成本，而又不会使系统不及时响应。

优势：有非常好的平均响应时间，通过设置合适的时间片，能获得不错的性能

缺点：较差的平均周转时间

![image-20211123081045212](https://gitee.com/nnilk/cloudimage/raw/master/img/202111230810271.png)

#### **结合IO**

当一个交互性进程发出IO让出CPU后，调度程序调度其他程序，从而更好地利用CPU![image-20211111210429081](https://gitee.com/nnilk/cloudimage/raw/master/img/202111112104131.png)

### 课后习题

**7.1**

**使用 SJF 和 FIFO 调度程序运行长度为 200 的 3 个作业时,计算响应时间和周转时间。**

| 作业ID | 响应时间         | 周转时间         |
| ------ | ---------------- | ---------------- |
| SJF    | 平均响应时间:200 | 平均周转时间:400 |
| 1      | 0                | 200              |
| 2      | 200              | 400              |
| 3      | 400              | 600              |
| FIFO   | 平均响应时间:200 | 平均周转时间:400 |
| 1      | 0                | 200              |
| 2      | 200              | 400              |
| 3      | 400              | 600              |

**7.2**

现在做同样的事情,但有不同长度的作业,即 100、200 和 300

| 作业ID | 响应时间            | 周转时间            |
| ------ | ------------------- | ------------------- |
| SJF    | 平均响应时间：133.3 | 平均周转时间：333.3 |
| 1      | 0                   | 100                 |
| 2      | 100                 | 300                 |
| 3      | 300                 | 600                 |
| FIFO   | 平均响应时间：133.3 | 平均周转时间：333.3 |
| 1      | 0                   | 100                 |
| 2      | 100                 | 300                 |
| 3      | 300                 | 600                 |



**7.3**

**现在做同样的事情,但采用 RR 调度程序,时间片为 1**

| 作业ID | 响应时间        | 周转时间          |
| ------ | --------------- | ----------------- |
| RR     | 平均响应时间：2 | 平均周转时间：599 |
| 1      | 1               | 598               |
| 2      | 2               | 599               |
| 3      | 3               | 600               |

当三件工作时间分别为100,200,300时

| 作业ID | 响应时间        | 周转时间             |
| ------ | --------------- | -------------------- |
| RR     | 平均响应时间：2 | 平均周转时间：456.67 |
| 1      | 1               | 298                  |
| 2      | 2               | 499                  |
| 3      | 3               | 600                  |

**7.4**

**对于什么类型的工作负载,SJF 提供与 FIFO 相同的周转时间?**

以第一条：作业列表中的作业到达时间全部不一致。
第二，当作业到达时间一致时，在极细微可以忽略不计的时间上，作业列表中的作业排序必须按作业长度非严格递增。
第三，当有的作业到达时间一致，有的不一致时，到达时间一致的作业满足第二条。

**7.5**

**对于什么类型的工作负载和量子长度,SJF 与 RR 提供相同的响应时间?**

当运行时间小于等于时间片的时候，SJF和RR提供相同的响应时间

**7.6**

**随着工作长度的增加,SJF 的响应时间会怎样?**

随着工作长度的增加，SJF的响应时间越来越长

**7.7**

**随着量子长度的增加,RR 的响应时间会怎样?你能写出一个方程,计算给定 N 个工作时,最坏情况的响应时间吗?**

随着量子长度的增加，RR的平均响应时间会增加

假设k个工作n1,n2,n3..nk

工作长度为t1,t2...tk且t1>t2>...tk

最坏情况的平均响应时间为

averT=(t1+t1+t2+t1+t2+t3+t1+t2+t3...)/k=((k-1)t1+(k-2)t2+...tk-1)/k

## 第八章—调度：多级反馈队列（MLFQ）

### 知识点

**MLFQ（多级反馈队列）**

有许多独立的队列，每个列有不同的优先级。并利用反馈信息决定某个工作的优先级。一个工作只能处于一个队列中。MLFQ总是优先执行优先级高的工作。对于一个队列中的工作，我们采取轮转调度

规则1：如果A的优先级大于B优先级，运行A

规则2：如果A的优先级=B，轮转运行A和B

**尝:1：改变优先级**

规则3：工作进入系统时，放在最高优先级

规则4a：工作用完整个时间片后，降低其优先级（移入下一个队列）

规则4b：如果工作在其时间片内主动释放cpu，则优先级不变

**当前存在的问题**

饥饿问题，如果一个程序总是在时间片用完之前让出cpu，那么它将永远占据高优先级，导致长工作饿死

存在愚弄程序，使一个程序总是在时间片用完之前让出cpu，它将永远占据高优先级

一个程序不同时间表现不同，一个刚开始计算密集型程序可能在某段时间表现为交互性，那么他无法享受到交互性的待遇

**尝试2：提升优先级**

周期性地提升（boost）所有工作的优先级

规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。

**尝试 3：更好的计时方式**

规则 4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）

**其他问题**

1.如何配置一个调度程序，例如，配置多少队列？每一层队列的时间片配置多大？

大多数的 MLFQ 变体都支持不同队列可变的时间片长度。高优先级队列通常只有较短的时间片（比如 10ms 或者更少），因而这一层的交互工作可以更快地切换。相反，低优先级队列中更多的是 CPU 密集型工作，配置更长的时间片会取得更好的效果。

**MLFQ优点**

1.它不需要对工作的运行方式有先验知识，而是通过观察工作的运行来给出对应的优先级

2.MLFQ 可以同时满足各种工作的需求：对于短时间运行的交互型工作，获得类似于 SJF/STCF 的很好的全局性能，同时对长时间运行的CPU 密集型负载也可以公平地、不断地稳步向前。

因此，许多系统使用某种类型的 MLFQ作为自己的基础调度程序，包括类 BSD UNIX 系统[LM+89，B86]、Solaris[M06]以及 WindowsNT 和其后的 Window 系列操作系统。

### 课后习题

**8.1**

**只用两个工作和两个队列运行几个随机生成的问题。针对每个工作计算 MLFQ 的执行记录。限制每项作业的长度并关闭 I/O，让你的生活更轻松。**

执行命令行  python2 mlfq.py -j 2 -n 2 -M 0 -m 15 -s 1

程序运行结果如图

|      | 到达时间 | 占用cpu时间    | 完成时间 | 总执行时间 | 是否调用io |
| ---- | -------- | -------------- | -------- | ---------- | ---------- |
| job0 | 0        | 0-1（位于Q1）  | 1        | 2          | 否         |
| job1 | 0        | 2-11（位于Q2） | 11       | 11         | 否         |

![image-20211109210002760](https://gitee.com/nnilk/cloudimage/raw/master/img/202111101943355.png)



**8.3**

**将如何配置调度程序参数，像轮转调度程序那样工作？**

因为对于同一个队列中的工作，采取轮转的方式调度。所以将队列数设为1即可

**8.5**

**给定一个系统，其最高队列中的时间片长度为 10ms，你需要如何频繁地将工作推回到最高优先级级别（带有-B 标志），以保证一个长时间运行（并可能饥饿）的工作得到至少5%的 CPU？**

保证参数B小于等于190，这样至少每隔200ms这个长时间运行工作就能被执行10ms（5%）



## 第九章

### 知识点

#### **彩票调度**

彩票数（ticket）代表了进程（或用户或其他）占有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额。

**一个简单的例子**

![image-20211111105425418](https://gitee.com/nnilk/cloudimage/raw/master/img/202111111054744.png)

**优势**

彩票调度最精彩的地方在于利用了随机性
随机方法相对于传统的决策方式，至少有 3 点优势。

第一，随机方法常常可以避免奇怪的边角情况
第二，随机方法很轻量，几乎不需要记录任何状态。
第三，随机方法很快。只要能很快地产生随机数，做出决策就很快

**彩票调度机制**

1、一种方式是利用彩票货币（ticket currency）的概念。这种方式允许拥有一组彩票的用户以他们喜欢的某种货币，将彩票分给自己的不同工作。之后操作系统再自动将这种货币兑换为正确的全局彩票。

eg：假设用户 A 和用户 B 每人拥有 100 张彩票。用户 A 有两个工作 A1 和 A2，他以自己的货币，给每个工作 500 张彩票（共 1000 张）。用户 B 只运行一个工作，给它 10 张彩票（总共 10 张）。操作系统将进行兑换，将 A1 和 A2 拥有的 A 的货币 500 张，兑换成全局货币 50 张。类似地，兑换给 B1 的 10 张彩票兑换成 100 张。然后会对全局彩票货币（共 200张）举行抽奖，决定哪个工作运行。

2、彩票转让，一个进程可以临时将自己的彩票交给另一个进程。

3、彩票通胀（ticket inflation）有时也很有用。利用通胀，一个进程可以临时提升或降低自己拥有的彩票数量。

**代码实现**

要让这个过程更有效率，建议将列表项按照彩票数递减排序

```
1 // counter: used to track if we've found the winner yet
2 int counter = 0;
3
4 // winner: use some call to a random number generator to
5 // get a value, between 0 and the total # of tickets
6 int winner = getrandom(0, totaltickets);
7
8 // current: use this to walk through the list of jobs
9 node_t *current = head;
10
11 // loop until the sum of ticket values is > the winner
12 while (current) {
13 counter = counter + current->tickets;
14 if (counter > winner)
15 break; // found the winner
16 current = current->next;
17 }
18 // 'current' is the winner: schedule it...
```

#### 步长调度

确定性的公平分配算法

步长调度也很简单。系统中的每个工作都有自己的步长，这个值与票数值成反比。当需要进行调度时，选择目前拥有最小行程值的进程，并且在运行之后将该进程的行程值增加一个步长。

**一个例子**

A、B、C 这3 个工作的票数分别是100、50 和250，我们通过用一个大数分别除以他们的票数来获得每个进程的步长。比如用10000 除以这些票数值，得到了3 个进程的步长分别为100、200 和40。我们称这个值为每个进程的步长（stride）。每次进程运
行后，我们会让它的计数器 [称为行程（pass）值] 增加它的步长，记录它的总体进展。

可以看出，C 运行了 5 次、A 运行了 2 次，B 一次，正好是票数的比例——200、100 和 50。彩票调度算法只能一段时间后，在概率上实现比例，而步长调度算法可以在每个调度周期后做到完全正确。

![image-20211111110512549](https://gitee.com/nnilk/cloudimage/raw/master/img/202111111105771.png)

**优势**

步长调度能实现一个确定性的公平分配算法。

随机方式可以使得调度程序的实现简单（且大致正确），但偶尔并不能产生正确的比例，尤其在工作运行时间很短的情况下。

**劣势**

彩票调度有一个步长调度没有的优势——不需要全局状态。因此彩票调度算法能够更合理地处理新加入的进程。

#### 总结

比例份额调度的两种实现：彩票调度和步长调度。但这两种方法没有作为 CPU 调度程序被广泛使用

原因一：这两种方式都不能很好地适合 I/O[AC97]

原因二：没有解决如何分配彩票的问题

原因三：彩票调度在工作执行时间很短时，平均不公平度非常糟糕。只有当工作执行非常多的时间片时，彩票调度算法才能得到期望的结果。

原因四：步长调度需要全局状态，不能很好的解决新加入的进程

比例份额调度程序只有在这些问题可以相对容易解决的领域更有用（例如容易确定份额比例）。例如在虚拟（virtualized）数据中心中，你可能会希望分配1/4 的CPU 周期给Windows 虚拟机，剩余的给Linux 系统，比例分配的方式可以更简单高效。

### 课后习题

**9.1**

**计算 3 个工作在随机种子为 1、2 和 3 时的模拟解。**

运行命令行python2 lottery.py -j 3 -s 1，随机种子为1

可以看到，

时间片R=1

job0 ，总占用时间：1，彩票数：0-83

job1 ，总占用时间：7，彩票数：84-108

job2 ，总占用时间：2，彩票数：109-152

产生的随机数依次取模得到执行作业的顺序为：

2 0 1 2 2 2 1 1 1 1 1 1

![image-20211111112849348](https://gitee.com/nnilk/cloudimage/raw/master/img/202111111128405.png)

运行命令行python2 lottery.py -j 3 -s 2，随机种子为2

同理可得到执行作业的顺序：

2 0 0 2 0 1 0 2 0 0 0 1 0 0 1 2 1 1 1 2 1 1 2

![image-20211111113351023](https://gitee.com/nnilk/cloudimage/raw/master/img/202111111133096.png)

运行命令行python2 lottery.py -j 3 -s 3，随机种子为3

同理可得到执行作业的顺序：

1 1 0 1 0 2 2 2 2 2 2

![image-20211111113449142](https://gitee.com/nnilk/cloudimage/raw/master/img/202111111134211.png)

**9.2**

**现在运行两个具体的工作：每个长度为 10,但是一个（工作 0)只有一张彩票，另一个（工作 1)有 100 张（-l 10:1,10:100).彩票数量如此不平衡时会发生什么？在工作 1 完成之前，工作 0 是否会运行？多久？一般来说，这种彩票不平衡对彩票调度的行为有什么影响？**

只有一张彩票被调度的可能性非常小，可能会饿死。

在工作1完成之前，工作0可能会运行。

这种行为可能会导致平均周转和响应时间变得很差

**9.3**

**如果运行两个长度为 100 的工作，都有 100 张彩票（-l 100:100,100:100),调度程序有多不公平？运行一些不同的随机种子来确定（概率上的）答案。不公平性取决于一项工作比另一项工作早完成多少。**

分别运行命令行

python2 lottery.py -l 100:100,100:100 -s 1 -c

python2 lottery.py -l 100:100,100:100 -s 25 -c

python2 lottery.py -l 100:100,100:100 -s 50 -c

python2 lottery.py -l 100:100,100:100 -s 100 -q 10 -c(调整时间片为10)

python2 lottery.py -l 100:100,100:100 -s 100 -q 30 -c(调整时间片为30)

可以看到随机种子为1时 job0在192时完成，job1在200的时候完成

随机种子为25时 job1在182时完成，job0在200的时候完成

随机种子为50时 job1在188时完成，job0在200的时候完成

公平性都还不错

可以看到当时间片调整为10后，job1在140时完成，job0在200的时候完成

当时间片调整为30后，job1在150时完成，job0在240的时候完成

公平性较差

一般来说，时间片越小，两个工作完成的时间越接近，公平性越高

![image-20211111114313728](https://gitee.com/nnilk/cloudimage/raw/master/img/202111111143789.png)



## 第十章——多处理器调度

**多处理器架构**

**缓存一致性（cache coherence）问题**

与单处理器的核心区别在于对硬件缓存（cache）的使用，事实证明，多CPU 的情况下缓存要复杂得多。例如，假设一个运行在CPU 1 上的程序从内存地址A 读取数据。由于不在CPU 1 的缓存中，所以系统直接访问内存，得到值D。程序然后修改了地址A 处的值，只是将它的缓存更新为新值D'。将数据写回内存比较慢，因此系统（通常）会稍后再做。假设这时操作系统中断了该程序的运行，并将其交给CPU 2，重新读取地址A 的数据，由于CPU 2 的缓存中并没有该数据，所以会直接从内存中读取，得到了旧值D，而不是正确的值D'。

基本解决方案：通过监控内存访问，硬件可以保证获得正确的
数据，并保证共享内存的唯一性。在基于总线的系统中，一种方式是使用总线窥探（bus snooping）[G83]。每个缓存都通过监听链接所有缓存和内存的总线，来发现内存访问。如果CPU 发现对它放在缓存中的数据的更新，会作废（invalidate）本地副本（从缓存中移除），
或更新（update）它（修改为新值）。回写缓存。

**缓存亲和度（cache affinity**）
一个进程在某个CPU 上运行时，会在该CPU 的缓存中维护许多状态。下次该进程在相同CPU 上运行时，由于缓存中的数据而执行得更快。相反，在不同的CPU 上执行，会由于需要重新加载数据而很慢（好在硬件保证的缓存一致性可以保证正确执行）。因此多处理器调度应该考虑到这种缓存亲和性，**并尽可能将进程保持在同一个CPU 上**

**单队列调度**（SQMS）

简单地复用单处理器调度的基本架构，将所有需要调度的工作放入一个单独的队列中。

优点：能够从单CPU 调度程序很简单地发展而来

短板：它的扩展性不好（由于同步开销有限），并且不能很好地保证缓存亲和度。

调度程序的开发者需要在代码中通过加锁（locking）来保证原子性

为了解决缓存亲和性这个问题，大多数SQMS 调度程序都引入了一些亲和度机制，尽可能让进程在同一个CPU 上运行。保持一些工作的亲和度的同时，可能需要牺牲其他工作的亲和度来实现负载均衡

**多队列调度**MQMS

有些系统使用了多队列的方案，比如每个CPU一个队列。我们称之为多队列多处理器调度。基本调度框架包含多个调度队列，每个队列可以使用不同的调度规则

优势：具有可扩展性和缓存亲和性，所有工作都保持在固定的CPU上

短板：负载不均衡（每个CPU承载的工作不平衡），

解决方案：**工作迁移**，通过工作的跨CPU迁移。

**工作窃取**，工作量较少的（源）队列不定期地“偷看”其他（目标）队列是不是比自己的工作多。如果目标队列比源队列（显著地）更满，就从目标队列“窃取”一个或多个工作，实现负载均衡。

